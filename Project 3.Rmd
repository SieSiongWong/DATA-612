---
title: "Project 3"
author: "Sie Siong Wong"
date: "6/19/2020"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
theme: lumen
---

# Introduction

The goal of this project is to practice working with Matrix Factorization techniques. The task is to implement a matrix factorization method. But I will create movie recommender systems using the Singular Value Decomposition (SVD), Funk Singular Value Decomposition (SVDF), and Alternating Least Squares (ALS) algorithms available from the recommenderlab package, and evaluate and compare the accuracy of these 3 techniques. 


# Load R Packages

```{r, eval=TRUE, warning=FALSE, message=FALSE}

# Load required packages
library(tidyverse)
library(recommenderlab)
library(psych)
library(reshape2)
library(ggpubr)
library(purrr)

```


# Load Data

Both the movies and ratings datasets are taken from https://grouplens.org/datasets/movielens/latest/. There are two versions of these datasets. The small datasets are chosen due to limited computing power available on my laptop. 

```{r, eval=TRUE}

# Load movies and ratings datasets
movies <- read.csv("https://raw.githubusercontent.com/SieSiongWong/DATA-612/master/movies.csv")

ratings <- read.csv("https://raw.githubusercontent.com/SieSiongWong/DATA-612/master/ratings.csv")

head(movies)
head(ratings)

```


# Data Exploration & Preprocessing

## Statistic Summary

The movies dataset contain 3 columns and 9742 observations. The ratings dataset contain 4 columns and 100,836 observations.

We can see that the mean of the rating variable is at 3.5 and the standard deviation is 1.04 and the distribution is left skewed a little.

```{r, eval=TRUE}

# Summary of movies and ratings datasets
str(movies)
str(ratings)

# Statistical summary of rating variable
describe(ratings$rating)

```

## Matrix Conversion

First of all, we have to convert the raw dataset into matrix format that can be used for building recommendation systems through the recommenderlab package.

```{r, eval=TRUE}

# Convert to rating matrix
ratings_matrix <- dcast(ratings, userId~movieId, value.var = "rating", na.rm = FALSE)
  
# remove userid column
ratings_matrix <- as.matrix(ratings_matrix[,-1])
  
# Convert rating matrix into a recommenderlab sparse matrix
ratings_matrix <- as(ratings_matrix, "realRatingMatrix")

ratings_matrix

```

Each row of the ratings_matrix corresponds to a user, and each column corresponds to a movie id. There are more than 610 x 9724 = 5,931,640 combinations between a user and a movie id. So, it requires 5,931,640 cells to build the matrix. As we know that not every user has watched every movie. There are only 100,836 observations, so this matrix is sparse.

## Exploring the Values of the Rating

```{r, eval=TRUE}

# Convert the ratings matrix into a vector
vec_ratings <- as.vector(ratings_matrix@data)

# Unique ratings
unique(vec_ratings)

# Count the occurrences for each rating
table_ratings <- table(vec_ratings)

table_ratings

```

As we know a rating equal to 0 means a missing value in the matrix, so we can remove all of them before building a frequency plot of the ratings to visualize the ratings distribution.

```{r, eval=TRUE}

# Remove zero rating and convert the vector to factor
vec_ratings <- vec_ratings[vec_ratings != 0] %>% factor()

# Visualize through qplot
qplot(vec_ratings, fill = I("steelblue")) + 
  ggtitle("Distribution of the Ratings") + 
  labs(x = "Ratings")

```

## Explore Most Viewed Movies

```{r, eval=TRUE}

# Search for the top 10 most viewed movies
most_views <- colCounts(ratings_matrix) %>% melt()

most_views <- tibble::rowid_to_column(most_views, "movieId") %>% 
  rename(count = value) %>% 
  merge(movies, by = "movieId") %>% 
  top_n(count, n = 10)

# Visualize the top 10 most viewed movies
ggplot(most_views, aes(x = reorder(title, count), y = count, fill = 'lightblue')) + 
  geom_bar(stat = "identity") + 
  theme(axis.text.x =element_text(angle = 60, hjust = 1)) + 
  ggtitle("Top 10 Most Viewed Movies") + 
  theme(legend.position = "none", axis.title.x = element_blank())

```

## Explore the Average Ratings

```{r, eval=TRUE, message=FALSE}

# Average rating for each movie
avg_ratings_mv <- colMeans(ratings_matrix)

# Average rating for each user
avg_ratings_us <- rowMeans(ratings_matrix)

# Visualize the distribution of the average movie rating
avg1 <- qplot(avg_ratings_mv) + 
  stat_bin(binwidth = 0.1) +
  ggtitle("Average Movie Rating Distribution") + 
  labs(x = 'Average Rating', y = 'Frequency') 

# Visualize the distribution of the average user rating
avg2 <- qplot(avg_ratings_us) + 
  stat_bin(binwidth = 0.1) +
  ggtitle("Average User Rating Distribution") + 
  labs(x = 'Average Rating', y = 'Frequency') 

figure <- ggarrange(avg1, avg2, ncol = 1, nrow = 2)

figure

```

From both of the plots above, we can see that there are some movies have only few ratings and some users only rated few movies. For building recommendation systems, we don't want take these movies and users into account as these ratings might be biased. To remove these least-watched movies and least-rated users, we can set a threshold of minimum number for example, 50.

```{r, eval=TRUE, message=FALSE}

# Filter users and movies more than 50 
ratings_matrix <- ratings_matrix[rowCounts(ratings_matrix) > 50, colCounts(ratings_matrix) > 50]

# Average rating for each movie
avg_ratings_mv2 <- colMeans(ratings_matrix)

# Average rating for each user
avg_ratings_us2 <- rowMeans(ratings_matrix)

# Visualize the distribution of the average movie rating
avg3 <- qplot(avg_ratings_mv2) + 
  stat_bin(binwidth = 0.1) +
  ggtitle("Average Movie Rating Distribution") + 
  labs(x = 'Average Rating', y = 'Frequency')

# Visualize the distribution of the average user rating
avg4 <- qplot(avg_ratings_us2) + 
  stat_bin(binwidth = 0.1) +
  ggtitle("Average User Rating Distribution") + 
  labs(x = 'Average Rating', y = 'Frequency')

figure2 <- ggarrange(avg1, avg2, avg3, avg4, 
                     labels = c("A", "B", "C", "D"), 
                     ncol = 2, nrow = 2)

figure2

```

The effect of removing those potential biased ratings to the distribution is obvious. From above figure, we can see that the curve is much narrow and has less variance compared to before. 


# Recommenderlab

Let's see what are some of the recommender options are available from the recommenderlab package applicable to the realRatingMatrix objects for building recommendation systems.

```{r, eval=TRUE}

# Display the list of options for real rating matrix 
rec <-  recommenderRegistry$get_entries(dataType = "realRatingMatrix")
names(rec)

```

"SVD_realRatingMatrix", "SVDF_realRatingMatrix", "ALS_realRatingMatrix" are the three models used to demonstrate in this project. SVD_realRatingMatrix is the SVD approximation with column-mean imputation. SVDF_realRatingMatrix is the Funk SVD with stochastic gradient descend. ALS_realRatingMatrix is the ALS based on latent factors.

```{r, eval=TRUE}

# Description for the SVD method
lapply(rec, `[[`, 'description') %>%  `[[`('SVD_realRatingMatrix')

# Description for the SVDF method
lapply(rec, `[[`, 'description') %>%  `[[`('SVDF_realRatingMatrix')

# Description for the SVDF method
lapply(rec, `[[`, 'description') %>%  `[[`('ALS_realRatingMatrix')

# Default parameter values for the SVD method
rec$SVD_realRatingMatrix$parameters

# Default parameter values for the SVDF method
rec$SVDF_realRatingMatrix$parameters

# Default parameter values for the ALS method
rec$ALS_realRatingMatrix$parameters

```


# Recommendation Models

## Split Dataset

We will build the recommender models by using the splitting method that randomly assign a predefined proportion of the users to the training set and all others to the test set. For this project, we allocate 80% of the dataset to the training set and 20% to the test set. 10 ratings per user will be given to the recommender to make predictions and the other ratings are held out for computing prediction accuracy.

```{r, eval=TRUE}

evaluation <- evaluationScheme(ratings_matrix, method = "split", train = 0.8, given = 10)

evaluation

train <- getData(evaluation, "train")
train

test_known <- getData(evaluation, "known")
test_known

test_unknown <- getData(evaluation, "unknown")
test_unknown

```

## SVD

Create a recommender based on SVD approximation with column-mean imputation and using 10 number of features (rank of approximation).

```{r, eval=TRUE}

# Create an item-based CF recommender using training data
rec_svd <- Recommender(data = train, method = "SVD",
                        parameter = list(k = 10))

# Create predictions for the test items using known ratings with type as ratings
pred_svd_acr <- predict(object = rec_svd, newdata = test_known, type = "ratings")

# Create predictions for the test items using known ratings with type as top n recommendation list
pred_svd_n <- predict(object = rec_svd, newdata = test_known, n = 5)

```

### Exploring the Recommender Model on the Test Set

Top 5 recommendations for the first 5 users.

```{r, eval=TRUE, message=FALSE}

# Recommendations for the first 5 users.
first_5_users <- pred_svd_n@items[1:5] %>% data.frame()
colnames(first_5_users) <- c("user1", "user2", "user3", "user4", "user5")
first_5_users <- first_5_users %>% melt() %>% 
  rename(movieId = value) %>% 
  merge(movies, by = "movieId") %>% 
  rename(users = variable) %>% 
  select(users:title) %>%
  group_by(users) %>% 
  mutate(id = 1:n()) %>% 
  spread(users, title, convert = TRUE) %>% 
  select(-id)

first_5_users

```

From the table, we can see that not every movie id in ratings dataset exist in movies dataset. That's why you'll see some user 1 and user 2 only have 4 recommendations. 

Distribution of the number of recommended movies

```{r, eval=TRUE, message=FALSE}

# Define a matrix with the recommendations to the test set users
rec_matrix <- as.matrix(data.frame(pred_svd_n@items))

# Define a vector with all recommendations
num_of_items <- factor(table(rec_matrix))

# Visualize the distribution of the number of recommended movies
qplot(num_of_items) + ggtitle("Distribution of the Number of Recommended Movies") + labs(x = "Number of Count")

```

We can see from above plot that most of the movies have been recommended only a few times, and a few movies have been recommended many times.

Top 5 most recommended movies

```{r, eval=TRUE, message=FALSE}

# Top 5 most recommended movies
top5_rec_mv <- num_of_items %>% data.frame()
top5_rec_mv <- cbind(movieId = rownames(top5_rec_mv), top5_rec_mv)
rownames(top5_rec_mv) <- 1:nrow(top5_rec_mv)
colnames(top5_rec_mv)[2] <- "count"
top5_rec_mv <- top5_rec_mv %>% 
  mutate_if(is.factor, ~ as.integer(levels(.x))[.x]) %>%
  merge(movies, by = "movieId") %>%
  top_n(count, n = 5)

top5_rec_mv <- top5_rec_mv[order(top5_rec_mv$count, decreasing = TRUE),] %>% 
  select(title)

top5_rec_mv

```

## SVDF

Create a recommender based on Funk SVD (SVDF) with stochastic gradient descend and using 10 number of features (rank of approximation).

```{r, eval=TRUE}

# Create an item-based CF recommender using training data
rec_svdf <- Recommender(data = train, method = "SVDF",
                        parameter = list(k = 10))

# Create predictions for the test items using known ratings with type as ratings
pred_svdf_acr <- predict(object = rec_svdf, newdata = test_known, type = "ratings")

# Create predictions for the test items using known ratings with type as top n recommendation list
pred_svdf_n <- predict(object = rec_svdf, newdata = test_known, n = 5)

```

### Exploring the Recommender Model on the Test Set

Top 5 recommendations for the first 5 users.

```{r, eval=TRUE, message=FALSE}

# Recommendations for the first 5 users.
first_5_users <- pred_svdf_n@items[1:5] %>% data.frame()
colnames(first_5_users) <- c("user1", "user2", "user3", "user4", "user5")
first_5_users <- first_5_users %>% melt() %>% 
  rename(movieId = value) %>% 
  merge(movies, by = "movieId") %>% 
  rename(users = variable) %>% 
  select(users:title) %>%
  group_by(users) %>% 
  mutate(id = 1:n()) %>% 
  spread(users, title, convert = TRUE) %>% 
  select(-id)

first_5_users

```

From the table, we can see that not every movie id in ratings dataset exist in movies dataset. That's why you'll see some user 1, user 2, and user 5 only have 4 recommendations. Compare to the SVD approximation method, you'll notice that the recommendations for the first 5 users are all different.

Distribution of the number of recommended movies

```{r, eval=TRUE, message=FALSE}

# Define a matrix with the recommendations to the test set users
rec_matrix <- as.matrix(data.frame(pred_svdf_n@items))

# Define a vector with all recommendations
num_of_items <- factor(table(rec_matrix))

# Visualize the distribution of the number of recommended movies
qplot(num_of_items) + ggtitle("Distribution of the Number of Recommended Movies") + labs(x = "Number of Count")

```

Compare to SVD approximation method, we can see from above plot that the number of the movies have been recommended much equally.

Top 5 most recommended movies

```{r, eval=TRUE, message=FALSE}

# Top 5 most recommended movies
top5_rec_mv <- num_of_items %>% data.frame()
top5_rec_mv <- cbind(movieId = rownames(top5_rec_mv), top5_rec_mv)
rownames(top5_rec_mv) <- 1:nrow(top5_rec_mv)
colnames(top5_rec_mv)[2] <- "count"
top5_rec_mv <- top5_rec_mv %>% 
  mutate_if(is.factor, ~ as.integer(levels(.x))[.x]) %>%
  merge(movies, by = "movieId") %>%
  top_n(count, n = 5)

top5_rec_mv <- top5_rec_mv[order(top5_rec_mv$count, decreasing = TRUE),] %>% 
  select(title)

top5_rec_mv

```

Compare to SVD approximation method, we can see the top 5 most recommended movies are different.

## ALS

Create a recommender based on Funk SVD (SVDF) with stochastic gradient descend.

```{r, eval=TRUE}

# Create an item-based CF recommender using training data
rec_als <- Recommender(data = train, method = "ALS")

# Create predictions for the test items using known ratings with type as ratings
pred_als_acr <- predict(object = rec_als, newdata = test_known, type = "ratings")

# Create predictions for the test items using known ratings with type as top n recommendation list
pred_als_n <- predict(object = rec_als, newdata = test_known, n = 5)

```

### Exploring the Recommender Model on the Test Set

Top 5 recommendations for the first 5 users.

```{r, eval=TRUE, message=FALSE}

# Recommendations for the first 5 users.
first_5_users <- pred_als_n@items[1:5] %>% data.frame()
colnames(first_5_users) <- c("user1", "user2", "user3", "user4", "user5")
first_5_users <- first_5_users %>% melt() %>% 
  rename(movieId = value) %>% 
  merge(movies, by = "movieId") %>% 
  rename(users = variable) %>% 
  select(users:title) %>%
  group_by(users) %>% 
  mutate(id = 1:n()) %>% 
  spread(users, title, convert = TRUE) %>% 
  select(-id)

first_5_users

```

From the table, we can see that not every movie id in ratings dataset exist in movies dataset. That's why you'll see some user 1, user 2, and user 3 have less than 5 recommendations. Compare to SVD approximation and SVDF methods, the recommendations for each user are different.

Distribution of the number of recommended movies

```{r, eval=TRUE, message=FALSE}

# Define a matrix with the recommendations to the test set users
rec_matrix <- as.matrix(data.frame(pred_als_n@items))

# Define a vector with all recommendations
num_of_items <- factor(table(rec_matrix))

# Visualize the distribution of the number of recommended movies
qplot(num_of_items) + ggtitle("Distribution of the Number of Recommended Movies") + labs(x = "Number of Count")

```

Compare to SVDF method, we can see the distribution looks like the result of SVD approximation method where most of the movies have been recommended only a few times, and a few movies have been recommended many times.

Top 5 most recommended movies

```{r, eval=TRUE, message=FALSE}

# Top 5 most recommended movies
top5_rec_mv <- num_of_items %>% data.frame()
top5_rec_mv <- cbind(movieId = rownames(top5_rec_mv), top5_rec_mv)
rownames(top5_rec_mv) <- 1:nrow(top5_rec_mv)
colnames(top5_rec_mv)[2] <- "count"
top5_rec_mv <- top5_rec_mv %>% 
  mutate_if(is.factor, ~ as.integer(levels(.x))[.x]) %>%
  merge(movies, by = "movieId") %>%
  top_n(count, n = 5)

top5_rec_mv <- top5_rec_mv[order(top5_rec_mv$count, decreasing = TRUE),] %>% 
  select(title)

top5_rec_mv

```

Again, compare to SVD approximation and SVDF methods, the top 5 most recommended movies are different except the Big Green, The (1995) movie is same as result from SVDF method.


# Evaluate & Compare

Evaluate the accuracy of SVD approximation, Funk SVD, and ALS recommenders on unknown ratings.

```{r, eval=TRUE}

# Evaluate the SVD approximated recommendations on unknown ratings
acr_svd <- calcPredictionAccuracy(pred_svd_acr, test_unknown)

# Evaluate the Funk SVD recommendations on unknown ratings
acr_svdf <- calcPredictionAccuracy(pred_svdf_acr, test_unknown)

# Evaluate the ALS recommendations on unknown ratings
acr_als <- calcPredictionAccuracy(pred_als_acr, test_unknown)

acr <- rbind(SVD = acr_svd, SVDF = acr_svdf, ALS = acr_als)

acr

```

Let's try another evaluation scheme with "Cross Validation" method with 5-fold cross validation.

```{r, eval=TRUE}

# Setup the evaluation scheme
evaluation_2 <- evaluationScheme(ratings_matrix, 
                                 method     = "cross", 
                                 k          = 5, 
                                 train      = 0.8, 
                                 given      = 10,
                                 goodRating = 3
                                 )

evaluation_2

# Set up list of algorithms
algorithms <- list(
  "SVD Approximation"           = list(name  = "SVD", parameter = list(k = 10)),
  "Funk SVD"                    = list(name  = "SVDF", parameter = list(k = 10)),
  "Alternating Least Squares"   = list(name  = "ALS")
                  )

# Estimate the models with top N recommendation lists
results <- evaluate(evaluation_2, 
                    algorithms, 
                    type  = "topNList", 
                    n     = c(1, 3, 5, 10, 15, 20)
                   )

results

# Create a function to get average of precision, recall, TPR, FPR
avg_cf_matrix <- function(results) {
avg <- results %>%
  getConfusionMatrix()  %>%  
  as.list()
  as.data.frame( Reduce("+", avg) / length(avg)) %>% 
  mutate(n = c(1, 3, 5, 10, 15, 20)) %>%  
  select('n', 'precision', 'recall', 'TPR', 'FPR')
}

# Using map() to iterate the avg function across both models
results_tbl <- results %>% map(avg_cf_matrix) %>% enframe() %>% unnest()

results_tbl

# Plot ROC curves for each model
results_tbl %>%
  ggplot(aes(FPR, TPR, color = fct_reorder2(as.factor(name), FPR, TPR))) +
  geom_line() +
  geom_label(aes(label = n))  +
  labs(title = "ROC Curves", color = "Model") +
  theme_grey(base_size = 14)

# Plot Precision-Recall curves for each model
results_tbl %>%
  ggplot(aes(recall, precision, color = fct_reorder2(as.factor(name), recall, precision))) +
  geom_line() +
  geom_label(aes(label = n))  +
  labs(title = "Precision-Recall Curves", colour = "Model") +
  theme_grey(base_size = 14)

```


# Summary

From both the evaluation results, the more advance technique Funk SVD (SVDF) model with stochastic gradient descent is the clear winner. We can see its RMSE and MAE are the lowest among the 3 models. Also, we can clearly see from the ROC curves that the SVDF model achieves higher True Positive Rate (TPR) for any given level of False Negative Rate (FPR) and has the highest area under the curve (AUC). This means that the SVDF model is producing higher number of relevant recommendations (true positives) for the same level of non-relevant recommendations (false positives). In addition to that, the SVDF model also has the highest AUC in Precision-Recall curves and achieves higher Precision for any given level of Recall. You notice that the values of Recall is one decimal digit smaller than the Precision values. This low recall and high precision means that the SVDF model is only returning few relevant recommendations but highly accurate.


# Reference

Gorakala, K.G. & Usuelli, M. (2015, Sept). Building a Recommendation System with R (pp. 50-92). Packt Publishing Ltd.

Hashler, M. & Vereet, B. (2019, Aug 27). Package ‘recommenderlab’. CRAN. Retrieved from https://cran.r-project.org/web/packages/recommenderlab/recommenderlab.pdf.















